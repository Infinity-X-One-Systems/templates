# Streaming Chat

A minimal Python template for consuming streaming token responses from LLM APIs.
Supports SSE, WebSocket, and Python generator streaming modes with buffered session state.
Replace `simulate_stream` with a real provider call to stream live responses.
